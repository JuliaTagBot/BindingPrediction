2016-03-21  Deniz Yuret  <dyuret@ku.edu.tr>

	* model05.jl: trying rnn model.  saw 62.6@4K with one lstm 32
	hidden.  try without adam?
	with 256 hidden: 64.2@8K, 65.8@16K, 66.95@32K, 67.95@64K
	(1,0.7670895f0,0.5)
	(2,0.7870218932628632,0.5)
	(4,0.790457211508155,0.5)
	(8,0.7887824499360889,0.4999249843750001)
	(16,0.7820475894107846,0.5017376894477075)
	(32,0.7674567686487525,0.5133441129336902)
	(64,0.7398459320816413,0.5397198113865014)
	(128,0.6877308620807926,0.5708688192357589)
	(256,0.6054717233889524,0.5938594454467707)
	(512,0.5693346123727129,0.608386887163344)
	(1024,0.5630231562766616,0.6128376101608914)
	(2048,0.5585068162888615,0.6111671552820388)
	(4096,0.5593190887857925,0.6195320647954465)
	(8192,0.5487005717722863,0.6418676054273353)
	(16384,0.5409262118008304,0.6578520411961633)
	(32768,0.5287464149346305,0.669545893339313)
	(65536,0.5204879012412502,0.6795305601652457)
	(131072,0.5232149835850248,0.6751933279964852)
	(262144,0.5247984440994684,0.6786203322967537)

2016-03-20  Deniz Yuret  <dyuret@ku.edu.tr>

	* model04.jl: vggnet model A from http://arxiv.org/pdf/1409.1556v6.pdf
	62@1K

	* model03.jl: more fc layers: add +.5% => 66.2@8K
	C=64,128,256
	F=256 %64@512 %65.4@1K 66.2@8K
	F=128 and 512 are similar
	F=128,128 %64.3@512 %65.6@1K 66.2@8K

	Longer run: (iter,softloss,1-error) with nbatch=128
	(16,0.7717592019118032,0.5067542147176836)
	(32,0.7471922323210548,0.521499697094878)
	(64,0.6986527361455038,0.5516034758784856)
	(128,0.6340780189803857,0.5882834592249624)
	(256,0.5712480153757631,0.6298053340609724)
	(512,0.5517600432731254,0.6417776660928463)
	(1024,0.5452585118039903,0.6530180761610829)
	(2048,0.5409149309070316,0.6581438928103153)
	(4096,0.5408834846403274,0.6582771821489561)
	(8192,0.5369208570946014,0.6645235420027924)
	(16384,0.5334389944026348,0.670336899997459)
	(32768,0.5288384511978679,0.6688833300227164)
	(65536,0.5205062706206457,0.6781443354108854)
	(131072,0.5238383187543814,0.6748884933349375)
	(262144,0.5267178587417906,0.6747090959623597)

	* model02.jl: more conv layers: add +1% => 65.8@8K
	C=64,128 %64@1K %65@8K
	C=128,256 similar
	C=64,128,256 %65@1K %65.8@8K
	C=64,128,256,512 %62.4@256 %63.8@512 %65.0@1K

	* model01.jl: initial experiments with a cbfp+wbf: 64.7@32K

	%63@1024 C=512 W=3 B=128
	crosses %64.7 @32K
	C=256 or C=512 not better, W=5 similar, tanh similar

	* TODO:
	# gclip
	# more conv layers
	# more fc layers
	# embedding layer
	# tanh vs relu

	* chars: there is N in addition to ACTG:

	* wc: each sequence is 51 long.  approx 25M positive 25M negative
	examples.  17M unique in each case.

	dyuret@biyofiz-4-0:~/alkan[0]$ zcat NeuroD2\ ChIP-SEQ-antibody1.fastq.gz | awk 'NR%4==2' | wc -l
	26767599
	dyuret@biyofiz-4-0:~/alkan[35]$ zcat GFP\ ChIP-SEQ-antibody1.fastq.gz | awk 'NR%4==2' | wc -l
	24495706
	dyuret@biyofiz-4-0:~/alkan[96]$ zcat NeuroD2\ ChIP-SEQ-antibody1.fastq.gz | awk 'NR%4==2' | rcount | wc -l
	17483930
	dyuret@biyofiz-4-0:~/alkan[0]$ zcat GFP\ ChIP-SEQ-antibody1.fastq.gz | awk 'NR%4==2' | rcount | wc -l
	17615277

	dyuret@biyofiz-4-0:~/alkan[0]$ zcat NeuroD2\ ChIP-SEQ-antibody1.fastq.gz | awk 'NR%4==2' | sort -u > foo.neuro.sortu
	dyuret@biyofiz-4-0:~/alkan[213]$ zcat GFP\ ChIP-SEQ-antibody1.fastq.gz  | awk 'NR%4==2' | sort -u > foo.gfp.sortu
	dyuret@biyofiz-4-0:~/alkan[182]$ wc -l *.sortu
	17615277 foo.gfp.sortu
	17483930 foo.neuro.sortu
	35099207 total
	dyuret@biyofiz-4-0:~/alkan[1]$ comm -12 *.sortu | wc -l
	553500
